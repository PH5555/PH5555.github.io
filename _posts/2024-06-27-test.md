---
layout: post
title: NLP
tags: [인공지능]
comments: true
---

## 방법론

텍스트 데이터에서 주제를 찾는 방법에는 크게 `Topic Modeling` 과 ` Text Clustering`이 있다.

## 전처리

기계학습에 있어서 데이터 전처리는 필수적이다. NLP를 위한 텍스트 데이터에는 다음과 같은 전처리를 진행할 수 있다.

1. URL, 이메일, 전화번호, 구두점 제거
2. 태그, 이모티콘, 기호 제거
3. 불용어 제거
4. 중복 제거
5. 맞춤법 제거

```
원본 리뷰: {'지루한 영화와 에피소드가 모두 포함되어 있습니다'} 
전처리된 리뷰: {'지루한 영화 에피소드'}
```

## 원 핫 인코딩

기계는 문자보다는 숫자를 더 잘 처리한다. 이를 위해서 문자를 숫자로 바꾸는 여러 방법이 있는데 `원 핫 인코딩`은 그 방법 중 제일 기본적인 방법이다.

> 단어 집합
> 서로 다른 단어들의 집합. 텍스트의 모든 단어를 중복을 허용하지 않고 모아놓으면 단어집합이라고 한다. 텍스트에 단어가 5000개면 단어집합도 5000개이고, 각 단어에 인덱스가 부여된다.

원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식이다.

"나는 자연어 처리를 배운다" 라는 문장을 예시로 들어보겠다.

`Okt 형태소 분석기`를 통해서 문장을 단어 단위로 나눈다. 결과로 ['나', '는', '자연어', '처리', '를', '배운다'] 배열이 나오게 된다.

그리고 해당 배열의 각 요소에 인덱스를 부여한다. 그리고 '자연어' 라는 단어의 `원 핫 벡터'를 추출해보면 [0, 0, 1, 0, 0, 0] 이 나오게 된다.

#### 한계점

먼저 단어의 갯수가 늘어날 수록 벡터도 늘어나서 공간이 낭비된다는 단점이 있다. 그리고 단어간의 유사도를 판별할 수 없다. 가령 `아산 숙소`라고 검색하면 `아산 호텔` `아산 게스트하우스` 와 같은 것도 같이 검색되면 좋지만 
유사도를 판별할 수 없어 불가능하다. 단어의 의미를 고려하여 다차원 벡터를 만든것이 LSA, worde2vec 등이 있다.

